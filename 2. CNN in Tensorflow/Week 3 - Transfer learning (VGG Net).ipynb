{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "height": 1000
    },
    "colab_type": "code",
    "id": "1xJZ5glPPCRz",
    "outputId": "6962a7b0-7a90-41b8-a129-dd85e93f0a06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-17 13:30:30--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.167.128, 2a00:1450:400c:c0c::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.167.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 87910968 (84M) [application/x-hdf]\n",
      "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
      "\n",
      "\r",
      "          /tmp/ince   0%[                    ]       0  --.-KB/s               \r",
      "         /tmp/incep  18%[==>                 ]  15.29M  76.4MB/s               \r",
      "        /tmp/incept  32%[=====>              ]  27.34M  68.3MB/s               \r",
      "       /tmp/incepti  72%[=============>      ]  60.59M   101MB/s               \r",
      "/tmp/inception_v3_w 100%[===================>]  83.84M   123MB/s    in 0.7s    \n",
      "\n",
      "2019-07-17 13:30:31 (123 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0717 13:30:32.502218 139854166521728 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling __init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 0\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Download the inception v3 weights\n",
    "!wget --no-check-certificate \\\n",
    "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
    "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "pre_trained_model = InceptionV3(\n",
    "    input_shape=(150, 150, 3),\n",
    "    include_top=False,\n",
    "    weights=None\n",
    ")\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Print the model summary\n",
    "pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "height": 34
    },
    "colab_type": "code",
    "id": "CFsUlwdfs_wg",
    "outputId": "65397e61-416a-48d3-d842-b51cc4d9b0fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('last layer output shape: ', (None, 7, 7, 768))\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.999):\n",
    "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "height": 1000
    },
    "colab_type": "code",
    "id": "BMXb913pbvFg",
    "outputId": "87bed2b0-7d9c-412e-efe2-a81acb4bac35"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0717 13:30:46.724679 139854166521728 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_impl.py:180: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense(1, activation='sigmoid')(x)           \n",
    "\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "model.compile(\n",
    "    optimizer=RMSprop(lr=0.0001), \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "height": 391
    },
    "colab_type": "code",
    "id": "HrnL_IQ8knWA",
    "outputId": "7e5e30e2-7711-4f87-988b-8dd1b5581e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-17 13:30:49--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.71.128, 2a00:1450:400c:c02::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.71.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 149574867 (143M) [application/zip]\n",
      "Saving to: ‘/tmp/horse-or-human.zip’\n",
      "\n",
      "/tmp/horse-or-human 100%[===================>] 142.65M  79.9MB/s    in 1.8s    \n",
      "\n",
      "2019-07-17 13:30:51 (79.9 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
      "\n",
      "--2019-07-17 13:30:52--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.76.128, 2a00:1450:400c:c06::80\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.76.128|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 11480187 (11M) [application/zip]\n",
      "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
      "\n",
      "/tmp/validation-hor 100%[===================>]  10.95M  --.-KB/s    in 0.09s   \n",
      "\n",
      "2019-07-17 13:30:52 (116 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the Horse or Human dataset\n",
    "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
    "\n",
    "# Get the Horse or Human Validation dataset\n",
    "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
    "  \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "local_zip = '//tmp/horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = '//tmp/validation-horse-or-human.zip'\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "height": 85
    },
    "colab_type": "code",
    "id": "y9okX7_ovskI",
    "outputId": "49e4626f-85fe-41fa-eb55-7fd2ffae1423"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = os.path.join(train_dir, 'horses') \n",
    "train_humans_dir = os.path.join(train_dir, 'humans') \n",
    "validation_horses_dir = os.path.join(validation_dir, 'horses')\n",
    "validation_humans_dir = os.path.join(validation_dir, 'humans')\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)\n",
    "train_humans_fnames = os.listdir(train_humans_dir)\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames))\n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "height": 51
    },
    "colab_type": "code",
    "id": "O4s8HckqGlnb",
    "outputId": "19d36357-42dd-4eea-a2ca-9c5ba2ade034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255.,\n",
    "    rotation_range = 40,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255.\n",
    ")\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    target_size=(150,150)\n",
    ")     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    batch_size=64,\n",
    "    class_mode='binary',\n",
    "    target_size=(150,150)\n",
    ")\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "Blhq2MAUeyGA",
    "outputId": "1b5ad2bc-1943-42af-c992-3d821c4e7019"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "17/17 [==============================] - 17s 978ms/step - loss: 0.4616 - acc: 0.8306 - val_loss: 0.0374 - val_acc: 1.0000\n",
      "Epoch 2/50\n",
      "17/17 [==============================] - 12s 718ms/step - loss: 0.1470 - acc: 0.9718 - val_loss: 0.0067 - val_acc: 0.9961\n",
      "Epoch 3/50\n",
      "17/17 [==============================] - 13s 754ms/step - loss: 0.1065 - acc: 0.9562 - val_loss: 0.0087 - val_acc: 0.9961\n",
      "Epoch 4/50\n",
      "17/17 [==============================] - 13s 747ms/step - loss: 0.0350 - acc: 0.9912 - val_loss: 6.8309e-04 - val_acc: 1.0000\n",
      "Epoch 5/50\n",
      "17/17 [==============================] - 13s 751ms/step - loss: 0.0771 - acc: 0.9718 - val_loss: 3.3632e-04 - val_acc: 1.0000\n",
      "Epoch 6/50\n",
      "17/17 [==============================] - 13s 761ms/step - loss: 0.0426 - acc: 0.9893 - val_loss: 3.2066e-04 - val_acc: 1.0000\n",
      "Epoch 7/50\n",
      "17/17 [==============================] - 13s 765ms/step - loss: 0.0422 - acc: 0.9834 - val_loss: 5.0213e-04 - val_acc: 1.0000\n",
      "Epoch 8/50\n",
      "17/17 [==============================] - 13s 768ms/step - loss: 0.0266 - acc: 0.9883 - val_loss: 2.4325e-04 - val_acc: 1.0000\n",
      "Epoch 9/50\n",
      "17/17 [==============================] - 13s 760ms/step - loss: 0.0289 - acc: 0.9932 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 10/50\n",
      "17/17 [==============================] - 13s 758ms/step - loss: 0.0965 - acc: 0.9766 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 11/50\n",
      "17/17 [==============================] - 13s 761ms/step - loss: 0.0214 - acc: 0.9932 - val_loss: 6.0944e-04 - val_acc: 1.0000\n",
      "Epoch 12/50\n",
      "17/17 [==============================] - 13s 756ms/step - loss: 0.0131 - acc: 0.9971 - val_loss: 0.0172 - val_acc: 0.9961\n",
      "Epoch 13/50\n",
      "17/17 [==============================] - 13s 761ms/step - loss: 0.0175 - acc: 0.9912 - val_loss: 4.8849e-04 - val_acc: 1.0000\n",
      "Epoch 14/50\n",
      "17/17 [==============================] - 13s 765ms/step - loss: 0.0199 - acc: 0.9922 - val_loss: 3.3018e-05 - val_acc: 1.0000\n",
      "Epoch 15/50\n",
      "17/17 [==============================] - 13s 761ms/step - loss: 0.0063 - acc: 0.9971 - val_loss: 2.3095e-04 - val_acc: 1.0000\n",
      "Epoch 16/50\n",
      "17/17 [==============================] - 13s 758ms/step - loss: 0.0202 - acc: 0.9932 - val_loss: 0.0880 - val_acc: 0.9805\n",
      "Epoch 17/50\n",
      "17/17 [==============================] - 13s 763ms/step - loss: 0.0556 - acc: 0.9922 - val_loss: 0.1658 - val_acc: 0.9727\n",
      "Epoch 18/50\n",
      "17/17 [==============================] - 13s 769ms/step - loss: 0.0367 - acc: 0.9981 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 19/50\n",
      "17/17 [==============================] - 13s 771ms/step - loss: 0.0126 - acc: 0.9961 - val_loss: 3.4716e-04 - val_acc: 1.0000\n",
      "Epoch 20/50\n",
      "16/17 [===========================>..] - ETA: 0s - loss: 0.0031 - acc: 1.0000\n",
      "Reached 99.9% accuracy so cancelling training!\n",
      "17/17 [==============================] - 13s 758ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 99.9% accuracy\n",
    "# (It should take less than 100 epochs)\n",
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    epochs=2,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[callbacks]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL",
    "outputId": "bc52dc0d-6274-430a-8f15-8ca19ee05d38"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
